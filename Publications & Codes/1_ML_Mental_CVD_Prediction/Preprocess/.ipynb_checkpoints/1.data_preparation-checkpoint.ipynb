{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e02ba1c9-098f-47cf-b261-28a628af6dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1c_q_1_results.csv', '1a_v_1_results.csv', '3a_v_1_results.csv', '2a_q_1_results.csv', '3b_q_1_results.csv', '2a_v_1_results.csv', '3a_q_2_results.csv', '3a_q_mini_results.csv', '1b_q_1_results.csv', '1a_q_1_results.csv', 'global_summary.csv', '2b_q_1_results.csv', '2a_q_2_results.csv', '3a_q_1_results.csv', '1a_q_2_results.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "path = \"/groups/umcg-lifelines/prm03/projects/ov20_0110/dataset_order_202501/results\"\n",
    "\n",
    "# List contents\n",
    "print(os.listdir(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b17def74-491b-4bac-92f4-abdfecfdba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_missing_values_and_uniques(df):\n",
    "    # Calculate missing values percentage (only true NaN values)\n",
    "    missing_values_sum = df.isna().sum()\n",
    "    total_rows = df.shape[0]\n",
    "    missing_values_percentage = (missing_values_sum / total_rows) * 100\n",
    "    print(\"Original missing values (%):\")\n",
    "    #print(missing_values_percentage.head(50))\n",
    "    \n",
    "    # Loop through each column\n",
    "    for column in df.columns:\n",
    "        print(f\"\\n--- Unique values for '{column}' ---\")\n",
    "        \n",
    "        # Special handling for ID columns\n",
    "        if column == 'project_pseudo_id':\n",
    "            num_unique = df[column].nunique()\n",
    "            print(f\"Total unique IDs: {num_unique} (expected 1 per participant)\")\n",
    "            print(f\"Duplicates found: {df[column].duplicated().sum()}\")\n",
    "            continue\n",
    "            \n",
    "        # Get value counts (including '$7' and other strings)\n",
    "        value_counts = df[column].value_counts(dropna=False).reset_index()\n",
    "        value_counts.columns = ['Unique Value', 'Count']\n",
    "        \n",
    "        # Calculate percentages safely\n",
    "        total_count = value_counts['Count'].sum()\n",
    "        \n",
    "        # Create percentage column with mixed types\n",
    "        percentages = []\n",
    "        for count in value_counts['Count']:\n",
    "            try:\n",
    "                pct = (float(count) / total_count) * 100\n",
    "                percentages.append(f\"{pct:.2f}%\")\n",
    "            except (TypeError, ValueError):\n",
    "                percentages.append(\"N/A\")\n",
    "        \n",
    "        value_counts['Percentage'] = percentages\n",
    "        display(value_counts)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6fb8ac4-f5d6-475f-9f39-89b2267a95da",
   "metadata": {},
   "outputs": [],
   "source": [
    "###CVD OUTCOME "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9496ac9-1440-400d-b7d1-86282b6aa06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file0 = \"2a_q_1_results.csv\" \n",
    "\n",
    "\n",
    "df = pd.read_csv(f\"{path}/{file0}\")\n",
    "\n",
    "\n",
    "\n",
    "# List of variables you want to show\n",
    "variables_to_show = ['project_pseudo_id', \n",
    "    'cvd_followup_adu_q_1', \n",
    "    'stroke_followup_adu_q_1', \n",
    "    'heartattack_followup_adu_q_1', \n",
    "    'claudication_followup_adu_q_1', \n",
    "  \n",
    "]\n",
    "\n",
    "\n",
    "# Filter the dataframe to show only these variables\n",
    "D0 = df[variables_to_show]\n",
    "\n",
    "\n",
    "# Define CVD variables\n",
    "cvd_variables = [\n",
    "    'cvd_followup_adu_q_1', \n",
    "    'stroke_followup_adu_q_1', \n",
    "    'heartattack_followup_adu_q_1',\n",
    "    'claudication_followup_adu_q_1',\n",
    "   \n",
    "]\n",
    "\n",
    "# Convert conditions to numpy arrays explicitly\n",
    "has_cvd = (D0[cvd_variables] == '1').any(axis=1).to_numpy()\n",
    "all_missing = (D0[cvd_variables] == '$7').all(axis=1).to_numpy()\n",
    "\n",
    "# Create output array with object dtype to hold mixed types\n",
    "result = np.empty(len(D0), dtype=object)\n",
    "\n",
    "# Apply conditions\n",
    "result[has_cvd] = 1\n",
    "result[all_missing] = '$7'\n",
    "result[(~has_cvd) & (~all_missing)] = 2\n",
    "\n",
    "D0['broad_cvd'] = result\n",
    "\n",
    "# Drop original follow-up columns and keep only project_pseudo_id + broad_cvd\n",
    "D0 = D0[['project_pseudo_id', 'broad_cvd']]\n",
    "\n",
    "# Count cases\n",
    "num_cases = D0[D0['broad_cvd'] == 1].shape[0]\n",
    "print(f\"Number of broad CVD cases: {num_cases}\")\n",
    "D0\n",
    "\n",
    "# aneurysm_diagnosis_adu_q_1\t1\tyes\tja\n",
    "# 1\taneurysm_diagnosis_adu_q_1\t2\tno\tnee\n",
    "# 2\tangioplasty_bypass_adu_q_1\t1\tyes\tja\n",
    "# 3\tangioplasty_bypass_adu_q_1\t2\tno\tnee\n",
    "# 4\tclaudication_followup_adu_q_1\t1\tyes\tja\n",
    "# 5\tclaudication_followup_adu_q_1\t2\tno\tnee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "486f1326-eb5a-4d56-a029-a8235dbe95b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Physical activity \n",
    "file1 = \"1a_q_2_results.csv\"  # Change to any file you want to inspect\n",
    "\n",
    "df1 = pd.read_csv(f\"{path}/{file1}\")\n",
    "df1.columns\n",
    "\n",
    "# List of variables you want to show\n",
    "variables_to_show = ['project_pseudo_id', 'squash_perweek_adu_q_15']\n",
    "\n",
    "# Filter the dataframe to show only these variables\n",
    "D1 = df1[variables_to_show]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4a9e802-e8cc-4d67-9831-7fe76877032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoking\n",
    "file2 = \"1a_q_2_results.csv\"  # Change to any file you want to inspect\n",
    "\n",
    "df2 = pd.read_csv(f\"{path}/{file2}\")\n",
    "df2.columns\n",
    "\n",
    "\n",
    "# # List of variables you want to show\n",
    "variables_to_show = [ 'project_pseudo_id', 'current_smoker_adu_c_2',\n",
    " 'ex_smoker_adu_c_2']\n",
    "\n",
    "# # Filter the dataframe to show only these variables\n",
    "D2 = df2[variables_to_show]\n",
    "\n",
    "\n",
    "D2_explained = analyze_missing_values_and_uniques(D2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d5a6b4c-507c-40ea-95b9-e42e18936aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#symptoms of depression and anxiety\n",
    "file3 = \"1a_v_1_results.csv\"\n",
    "df3 = pd.read_csv(f\"{path}/{file3}\")\n",
    "\n",
    "\n",
    "# Filter to include ALL MINI variants (v1, v2, v3)\n",
    "df3_mini = df3[df3['variant_id'].isin(['1a_v_1_mini_18plus_v1', \n",
    "                                 '1a_v_1_mini_18plus_v2', \n",
    "                                 '1a_v_1_mini_18plus_v3'])]\n",
    "\n",
    "mini_cols = [\n",
    "#depression symptoms \n",
    "            'mini_a_adu_q_1', #Depressed mood, #have you been consistently depressed or down, most of the day, nearly every day, for the past two weeks?\n",
    "            'mini_a_adu_q_2', #Anhedonia, in the past two weeks, have you been much less interested in most things or much less able to enjoy the things you used to enjoy most of the time?\n",
    "            'mini_a_adu_q_3_a',#Appetite changes, #was your appetite decreased or increased nearly every day? did your weight decrease or increase without trying intentionally?\n",
    "            'mini_a_adu_q_3_b',#Sleep problems #did you have trouble sleeping nearly every night (difficulty falling asleep, waking up in the middle of the night, early morning wakening or sleeping excessively)?\n",
    "            'mini_a_adu_q_3_c', #Psychomotor changes, did you talk or move more slowly than normal or were you fidgety, restless or having trouble sitting still almost every day?\n",
    "            'mini_a_adu_q_3_d', #Fatigue, did you feel tired or without energy almost every day?\n",
    "            'mini_a_adu_q_3_e', #Feelings of inadequacy, did you feel worthless or guilty almost every day?\n",
    "            'mini_a_adu_q_3_f', #Cognitive problems, did you have difficulty concentrating or making decisions almost every day?\n",
    "            'mini_a_adu_q_3_g',  #Suicidal ideation, did you repeatedly consider hurting yourself, feel suicidal, or wish that you were dead?\n",
    "\n",
    "\n",
    "#anxiety symptoms     \n",
    "         'mini_o_adu_q_1_a', #have you worried excessively or been anxious about several problems of daily life (problems at work, at home or in your close circle) over the past 6 months?\n",
    "        'mini_o_adu_q_3_a' , # when you were anxious in the past 6 months, did you, most of the time, feel restless, keyed up or on edge?\n",
    "         'mini_o_adu_q_3_b', #when you were anxious in the past 6 months, did you, most of the time, feel tense?\n",
    "        'mini_o_adu_q_3_c' , #when you were anxious in the past 6 months, did you, most of the time, feel tired, weak or exhausted easily?\n",
    "        'mini_o_adu_q_3_d', #when you were anxious in the past 6 months, did you, most of the time, have difficulty concentrating or find your mind going blank?\n",
    "        'mini_o_adu_q_3_e', #when you were anxious in the past 6 months, did you, most of the time, feel irritable?\n",
    "        'mini_o_adu_q_3_f' , #when you were anxious in the past 6 months, did you, most of the time, have difficulty sleeping (difficulty falling asleep, waking up in the middle of the night, early morning wakening or sleeping excessively)?               \n",
    "         \n",
    "]\n",
    "\n",
    "variables_to_show = ['project_pseudo_id'] + mini_cols  # Keep ID for reference\n",
    "D3 = df3_mini[variables_to_show]\n",
    "\n",
    "def clean_mini_data(df):\n",
    "    \"\"\"Clean MINI questionnaire data by standardizing values and handling missing codes\"\"\"\n",
    "    df = df.copy()\n",
    "    mini_cols = [col for col in df.columns if col.startswith('mini_')]\n",
    "    \n",
    "    for col in mini_cols:\n",
    "        # Convert $4 and similar to NaN\n",
    "        df[col] = df[col].replace(['$4', '$7', '$'], np.nan)\n",
    "        \n",
    "        # Convert all numeric responses to integers\n",
    "        df[col] = df[col].astype(str).str.extract('(\\d+)')[0]\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').astype('Int64')\n",
    "    \n",
    "    return df  # THIS WAS MISSING - NOW RETURNS THE CLEANED DF\n",
    "\n",
    "def analyze_missing_values_and_uniques(df, max_missing_pct=40):\n",
    "    \"\"\"Analyze missing values and unique value distributions, filtering by missingness percentage\"\"\"\n",
    "    analysis_results = []\n",
    "    \n",
    "    for column in df.columns:\n",
    "        # Calculate missing values\n",
    "        missing_count = df[column].isna().sum()\n",
    "        total_rows = len(df[column])\n",
    "        missing_pct = (missing_count / total_rows) * 100\n",
    "        \n",
    "        # Skip if missingness is too high\n",
    "        if missing_pct > max_missing_pct:\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n--- {column} ---\")\n",
    "        print(f\"Missing: {missing_count} ({missing_pct:.2f}%)\")\n",
    "        \n",
    "        # Special handling for ID columns - just show summary\n",
    "        if column == 'project_pseudo_id':\n",
    "            num_unique = df[column].nunique()\n",
    "            print(f\"Total unique IDs: {num_unique}\")\n",
    "            print(f\"Duplicates found: {df[column].duplicated().sum()}\")\n",
    "            analysis_results.append({\n",
    "                'variable': column,\n",
    "                'missing_count': missing_count,\n",
    "                'missing_pct': missing_pct,\n",
    "                'unique_count': num_unique,\n",
    "                'duplicates': df[column].duplicated().sum()\n",
    "            })\n",
    "            continue\n",
    "            \n",
    "        # Get value counts for non-ID columns\n",
    "        value_counts = df[column].value_counts(dropna=False).sort_index()\n",
    "        total = value_counts.sum()\n",
    "        \n",
    "        print(\"Value distribution:\")\n",
    "        for val, count in value_counts.items():\n",
    "            pct = (count / total) * 100\n",
    "            # Only show values that appear at least 1% of the time or are special codes\n",
    "            if pct >= 1 or str(val) in ['$4', '$7', '$']:\n",
    "                print(f\"  {val}: {count} ({pct:.2f}%)\")\n",
    "        \n",
    "        # Store results\n",
    "        analysis_results.append({\n",
    "            'variable': column,\n",
    "            'missing_count': missing_count,\n",
    "            'missing_pct': missing_pct,\n",
    "            'value_counts': {k: v for k, v in value_counts.items() \n",
    "                           if (v/total)*100 >= 1 or str(k) in ['$4', '$7', '$']}\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(analysis_results)\n",
    "\n",
    "# Clean and analyze with 50% missingness threshold\n",
    "D3_clean = clean_mini_data(D3)\n",
    "mini_stats = analyze_missing_values_and_uniques(D3_clean, max_missing_pct=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2cafe39-5d6a-40e1-ab9d-302376277947",
   "metadata": {},
   "outputs": [],
   "source": [
    "#symptoms of depression and anxiety\n",
    "file4 = \"1a_v_1_results.csv\"\n",
    "df4 = pd.read_csv(f\"{path}/{file4}\")\n",
    "df4['variant_id'].unique() \n",
    "\n",
    "df4 = df4[df4['variant_id'] == '1a_v_1_atc_18plus_v1']\n",
    "variables_to_show = [ 'project_pseudo_id', \n",
    "\n",
    "\n",
    " 'atc_code_adu_c_1_01',\n",
    " 'atc_code_adu_c_1_02',\n",
    " 'atc_code_adu_c_1_03',\n",
    " 'atc_code_adu_c_1_04',\n",
    " 'atc_code_adu_c_1_05',\n",
    " 'atc_code_adu_c_1_06',\n",
    " 'atc_code_adu_c_1_07',\n",
    " 'atc_code_adu_c_1_08',\n",
    " 'atc_code_adu_c_1_09',\n",
    " 'atc_code_adu_c_1_10',\n",
    " 'atc_code_adu_c_1_11',\n",
    " 'atc_code_adu_c_1_12',\n",
    " 'atc_code_adu_c_1_13',\n",
    " 'atc_code_adu_c_1_14',\n",
    " 'atc_code_adu_c_1_15',\n",
    " 'atc_code_adu_c_1_16',\n",
    " 'atc_code_adu_c_1_17',\n",
    " 'atc_code_adu_c_1_18',\n",
    " 'atc_code_adu_c_1_19',\n",
    " 'atc_code_adu_c_1_20',\n",
    " 'atc_code_adu_c_1_21',\n",
    " 'atc_code_adu_c_1_22',\n",
    " 'atc_code_adu_c_1_23',\n",
    " 'atc_code_adu_c_1_24',\n",
    " 'atc_code_adu_c_1_25',\n",
    " 'atc_code_adu_c_1_26',\n",
    " 'atc_code_adu_c_1_27',\n",
    " 'atc_code_adu_c_1_28',\n",
    " 'atc_code_adu_c_1_29',\n",
    " 'atc_code_adu_c_1_30',\n",
    " 'atc_code_adu_c_1_31',\n",
    " 'atc_code_adu_c_1_32',\n",
    "                     \n",
    "]\n",
    "\n",
    "# # # Filter the dataframe to show only these variables\n",
    "D4 = df4[variables_to_show]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "389be1cb-d1eb-45dd-b36e-f010dd69eb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antidepressant users: 8213/86457\n",
      "\n",
      "--- project_pseudo_id ---\n",
      "Missing: 0 (0.00%)\n",
      "Total unique IDs: 86457\n",
      "Duplicates found: 0\n",
      "\n",
      "--- Antidepressant ---\n",
      "Missing: 0 (0.00%)\n",
      "Value distribution:\n",
      "  0: 78244 (90.50%)\n",
      "  1: 8213 (9.50%)\n"
     ]
    }
   ],
   "source": [
    "# Define antidepressant ATC codes (strict N06A only)\n",
    "antidepressant_atc_codes = [\n",
    "    'N06A',  # All classic antidepressants\n",
    "    'N06CA'  # Psychostimulants (optional - remove if only want core antidepressants)\n",
    "]\n",
    "\n",
    "# Melt to identify antidepressant users\n",
    "df_long = D4.melt(\n",
    "    id_vars=['project_pseudo_id'],\n",
    "    value_vars=[col for col in D4.columns if col.startswith('atc_code_adu_c_1_')],\n",
    "    value_name='atc_code'\n",
    ")\n",
    "\n",
    "# Create antidepressant flag\n",
    "antidepressant_users = df_long[\n",
    "    df_long['atc_code'].str.startswith(tuple(antidepressant_atc_codes), na=False)\n",
    "]['project_pseudo_id'].unique()\n",
    "\n",
    "# Create new dataframe (drop all ATC columns, keep only flag)\n",
    "D4_new = D4.drop(\n",
    "    columns=[col for col in D4.columns if col.startswith('atc_code_adu_c_1_')]\n",
    ").assign(\n",
    "    Antidepressant=lambda x: x['project_pseudo_id'].isin(antidepressant_users).astype(int)\n",
    ")\n",
    "\n",
    "# Verify\n",
    "print(f\"Antidepressant users: {D4_new['Antidepressant'].sum()}/{len(D4_new)}\")\n",
    "\n",
    "\n",
    "D4_explained = analyze_missing_values_and_uniques(D4_new)\n",
    "\n",
    "\n",
    "#MAYBE INCLUDE LIDA TOO?\n",
    "# #Antidepressant\n",
    "# file6 = \"deaq_q_1_results.csv\"  # Change to any file you want to inspect\n",
    "\n",
    "\n",
    "# # List of variables you want to show\n",
    "# variables_to_show = ['project_pseudo_id','lidas_treatment_adu_q_03_b', 'lidas_treatment_adu_q_03_a' ]\n",
    "\n",
    "\n",
    "# # lidas_treatment_adu_q_03_a\t1\tnone of these treatments\t\n",
    "# # \tlidas_treatment_adu_q_03_b\t1\tantidepressants\t\n",
    "\n",
    "\n",
    "# # Read only the specified columns\n",
    "# D6 = pd.read_csv(f\"{path}/{file6}\", usecols=variables_to_show)\n",
    "\n",
    "# # If you need to see the columns\n",
    "# print(D6.columns)\n",
    "\n",
    "# # Convert columns to numeric\n",
    "# D6[\"lidas_treatment_adu_q_03_a\"] = pd.to_numeric(D6[\"lidas_treatment_adu_q_03_a\"], errors='coerce')\n",
    "# D6[\"lidas_treatment_adu_q_03_b\"] = pd.to_numeric(D6[\"lidas_treatment_adu_q_03_b\"], errors='coerce')\n",
    "\n",
    "# # Create the new variable 'Antidepressant'\n",
    "# D6[\"Antidepressant\"] = D6.apply(\n",
    "#     lambda row: 1 if row[\"lidas_treatment_adu_q_03_b\"] == 1 else (0 if row[\"lidas_treatment_adu_q_03_a\"] == 1 else None),\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2800d22-7be2-4262-91d0-281548d08c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load one file and check the first rows\n",
    "file5 = \"1a_q_1_results.csv\"  # Change to any file you want to inspect\n",
    "\n",
    "df5 = pd.read_csv(f\"{path}/{file5}\")\n",
    "df5.columns\n",
    "\n",
    "# # List of variables you want to show\n",
    "variables_to_show = ['project_pseudo_id', \n",
    "'diabetes_presence_adu_q_1', \n",
    "\n",
    " 'hypertension_treatment_adu_q_1', 'hypertension_presence_adu_q_1'\n",
    " ]\n",
    "\n",
    "# Filter the dataframe to show only these variables\n",
    "D5 = df5[variables_to_show]\n",
    "\n",
    "D5_explained = analyze_missing_values_and_uniques(D5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ddf5818-bf14-4a1b-b62b-830f6e2cb350",
   "metadata": {},
   "outputs": [],
   "source": [
    "#blood pressure\n",
    "file6 = \"1a_v_1_results.csv\"\n",
    "\n",
    "\n",
    "df6 = pd.read_csv(f\"{path}/{file6}\")\n",
    "\n",
    "\n",
    "df6 = df6[df6['variant_id'] == '1a_v_1_bp_8plus_v1']\n",
    "\n",
    "variables_to_show = ['project_pseudo_id', 'bpavg_diastolic_all_m_1', \n",
    "'bpavg_systolic_all_m_1']\n",
    "\n",
    "# # # Filter the dataframe to show only these variables\n",
    "D6 = df6[variables_to_show]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21979592-a3d4-4ca6-9ae2-4cb4adee23c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deaq_q_1_results.csv', 'depq_q_1_results.csv', '1b_q_1_results.csv', '1a_v_2_results.csv', 'global_summary.csv', 'salt_v_1_results.csv', '3a_v_2_results.csv', '2b_q_1_results.csv', '2a_v_2_results.csv']\n"
     ]
    }
   ],
   "source": [
    "path = \"/groups/umcg-lifelines/prm03/projects/ov20_0110/dataset_order_202502/Results\"\n",
    "\n",
    "# List contents\n",
    "print(os.listdir(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8247ca37-25a5-4c30-91ba-5dd3d6e2a93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#family history \n",
    "file7 = \"1b_q_1_results.csv\"  # Change to any file you want to inspect\n",
    "\n",
    "df7 = pd.read_csv(f\"{path}/{file7}\")\n",
    "df7.columns\n",
    "\n",
    "# # List of variables you want to show\n",
    "variables_to_show = ['project_pseudo_id','cvd_father_fam_q_1_a', 'cvd_father_fam_q_1_b', \n",
    "'cvd_father_fam_q_1_c', 'cvd_father_fam_q_1_d', 'cvd_father_fam_q_1_e', 'cvd_father_fam_q_1_f', \n",
    "'cvd_mother_fam_q_1_a', 'cvd_mother_fam_q_1_b', 'cvd_mother_fam_q_1_c', 'cvd_mother_fam_q_1_d', \n",
    "'cvd_mother_fam_q_1_e', 'cvd_mother_fam_q_1_f', 'cvd_siblings_fam_q_1_a', 'cvd_siblings_fam_q_1_b',\n",
    "'cvd_siblings_fam_q_1_c', 'cvd_siblings_fam_q_1_d', 'cvd_siblings_fam_q_1_e', 'cvd_siblings_fam_q_1_f' ]\n",
    "\n",
    "# # Filter the dataframe to show only these variables\n",
    "D7 = df7[variables_to_show]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cca104d-e524-40c7-9ae7-e2368f5616a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3268840/2011525499.py:4: DtypeWarning: Columns (24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df8 = pd.read_csv(f\"{path}/{file8}\")\n"
     ]
    }
   ],
   "source": [
    "#trauma  \n",
    "file8 = \"2b_q_1_results.csv\"  # Change to any file you want to inspect\n",
    "\n",
    "df8 = pd.read_csv(f\"{path}/{file8}\")\n",
    "df8.columns\n",
    "\n",
    "# # # List of variables you want to show\n",
    "variables_to_show = ['project_pseudo_id','ctq_emotionalabuse_adu_q_08', 'ctq_emotionalabuse_adu_q_18',\n",
    "    'ctq_emotionalneglect_adu_q_07', 'ctq_physicalabuse_adu_q_09',\n",
    "    'ctq_physicalabuse_adu_q_11', 'ctq_physicalabuse_adu_q_12',\n",
    "    'ctq_physicalabuse_adu_q_15', 'ctq_physicalabuse_adu_q_17',\n",
    "    'ctq_physicalneglect_adu_q_26', 'ctq_sexualabuse_adu_q_20',\n",
    "    'ctq_sexualabuse_adu_q_21', 'ctq_sexualabuse_adu_q_23',\n",
    "    'ctq_sexualabuse_adu_q_24', 'ctq_sexualabuse_adu_q_27' ]\n",
    "\n",
    "# # # Filter the dataframe to show only these variables\n",
    "D8 = df8[variables_to_show]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30895c65-b99f-4bfc-8661-ae21cfb866c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #biomarkers \n",
    "# file9 = \"1a_v_2_results.csv\"  # Change to any file you want to inspect\n",
    "# df9 = pd.read_csv(f\"{path}/{file9}\")\n",
    "# df9['variant_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5941262-b1f0-4a82-9f55-0253f3fb717d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# biomarkers \n",
    "file11 = \"1a_v_2_results.csv\"  # Change to any file you want to inspect\n",
    "\n",
    "df11 = pd.read_csv(f\"{path}/{file11}\")\n",
    "df11['variant_id'].unique()\n",
    "\n",
    "df11_ = df11[df11['variant_id'].isin([ '1a_v_2_bloodcells1_8plus_v1', '1a_v_2_bloodcells1_8plus_v2' ])] \n",
    "                                   \n",
    "\n",
    "\n",
    "# # # List of variables you want to show\n",
    "variables_to_show = ['project_pseudo_id', 'hba1cconc_result_all_m_1'] \n",
    "\n",
    "# # # Filter the dataframe to show only these variables\n",
    "D11 = df11_[variables_to_show]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b8c68ed-a43e-4d90-9725-1cb9ad18ba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#biomarkers \n",
    "file9 = \"1a_v_2_results.csv\"  # Change to any file you want to inspect\n",
    "\n",
    "df9 = pd.read_csv(f\"{path}/{file9}\")\n",
    "df9\n",
    "\n",
    "df9_ = df9[df9['variant_id'].isin(['1a_v_2_bloodplasma1_8plus_v1'     ,'1a_v_2_bloodplasma1_8plus_v2'])] \n",
    "                                   \n",
    "\n",
    "# # List of variables you want to show\n",
    "variables_to_show = ['project_pseudo_id','age','gender', 'cholesterol_result_all_m_1', 'hdlchol_result_all_m_1',\n",
    "                     'ldlchol_result_all_m_1',\n",
    "              'triglyceride_result_all_m_1', 'glucose_result_all_m_1'\n",
    "                   ] \n",
    "\n",
    "# # Filter the dataframe to show only these variables\n",
    "D9 = df9_[variables_to_show]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b14a1c9-f6a8-4663-8899-8dc53d1bc276",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import pandas as pd\n",
    "\n",
    "# List of DataFrames to merge\n",
    "dfs = [D0,\n",
    "D1,\n",
    "D2,\n",
    "D3_clean,\n",
    "D4_new,\n",
    "D5,\n",
    "D6,\n",
    "D7,\n",
    "D8,\n",
    "D9, D11]\n",
    "\n",
    "# Merge all DataFrames\n",
    "merged_df = reduce(lambda left, right: pd.merge(left, right, on='project_pseudo_id', how='outer'), dfs)\n",
    "\n",
    "# 2. Standardize all missing values to NaN (not <NA>)\n",
    "merged_df = merged_df.fillna(np.nan)\n",
    "# 1. Replace specified dollar values with NaN\n",
    "values_to_replace = ['$6', '$7', '$4', '$5']\n",
    "merged_df.replace(values_to_replace, np.nan, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "653a642f-94b2-4e05-b5de-13c30ce02dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.dropna(subset=['gender'])\n",
    "merged_df = merged_df.dropna(subset=['age'])\n",
    "merged_df = merged_df.dropna(subset=['broad_cvd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e7733aa-d31b-4197-ab6b-7699ceebc287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts in 'cvd_father_family_history':\n",
      "cvd_father_family_history\n",
      "NaN    66367\n",
      "1.0    31293\n",
      "0.0     2498\n",
      "Name: count, dtype: int64\n",
      "Value counts in 'cvd_father_family_history':\n",
      "cvd_mother_family_history\n",
      "NaN                          79128\n",
      "1.0                          17822\n",
      "0.0                           3208\n",
      "Name: count, dtype: int64\n",
      "Value counts in 'cvd_siblings_family_history':\n",
      "cvd_siblings_family_history\n",
      "NaN                            92551\n",
      "1.0                             7603\n",
      "0.0                                4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# cvd_father_fam_q_1_a\t1\tyes\t\n",
    "# \tcvd_father_fam_q_1_a\t2\tno\t\n",
    "# \tcvd_father_fam_q_1_a\t3\ti do not know\t\n",
    "\n",
    "# Define the columns related to family history\n",
    "cvd_columns = [\n",
    "    'cvd_father_fam_q_1_a', 'cvd_father_fam_q_1_b', 'cvd_father_fam_q_1_c',\n",
    "    'cvd_father_fam_q_1_d', 'cvd_father_fam_q_1_e', 'cvd_father_fam_q_1_f'\n",
    "]\n",
    "\n",
    "def calculate_family_history(row):\n",
    "    \"\"\"\n",
    "    Calculate family history of CVD for the father.\n",
    "    - If any column has a value of 1 (Yes), return 1 (Yes).\n",
    "    - If all columns have a value of 0 (No), return 0 (No).\n",
    "    - If all columns are NaN, return NaN (Missing).\n",
    "    \"\"\"\n",
    "    if (row == '1').any():  # If any column has a value of 1 (Yes)\n",
    "        return 1\n",
    "    elif (row == '2').all():  # If all columns have a value of 0 (No)\n",
    "        return 0\n",
    "    else:  # If all columns are NaN or a mix of NaN and 0\n",
    "        return np.nan\n",
    "\n",
    "# Apply the function to create the new variable\n",
    "merged_df['cvd_father_family_history'] = merged_df[cvd_columns].apply(calculate_family_history, axis=1)\n",
    "\n",
    "# Check the results\n",
    "print(\"Value counts in 'cvd_father_family_history':\")\n",
    "print(merged_df['cvd_father_family_history'].value_counts(dropna=False))\n",
    "\n",
    "\n",
    "# Define the columns related to family history\n",
    "cvd_columns = [\n",
    "    'cvd_mother_fam_q_1_a',\n",
    " 'cvd_mother_fam_q_1_b',\n",
    " 'cvd_mother_fam_q_1_c',\n",
    " 'cvd_mother_fam_q_1_d',\n",
    " 'cvd_mother_fam_q_1_e',\n",
    " 'cvd_mother_fam_q_1_f',\n",
    "]\n",
    "\n",
    "def calculate_family_history(row):\n",
    "    \"\"\"\n",
    "    Calculate family history of CVD for the father.\n",
    "    - If any column has a value of 1 (Yes), return 1 (Yes).\n",
    "    - If all columns have a value of 0 (No), return 0 (No).\n",
    "    - If all columns are NaN, return NaN (Missing).\n",
    "    \"\"\"\n",
    "    if (row == '1').any():  # If any column has a value of 1 (Yes)\n",
    "        return 1\n",
    "    elif (row == '2').all():  # If all columns have a value of 0 (No)\n",
    "        return 0\n",
    "    else:  # If all columns are NaN or a mix of NaN and 0\n",
    "        return np.nan\n",
    "\n",
    "# Apply the function to create the new variable\n",
    "merged_df['cvd_mother_family_history'] = merged_df[cvd_columns].apply(calculate_family_history, axis=1)\n",
    "\n",
    "# Check the results\n",
    "print(\"Value counts in 'cvd_father_family_history':\")\n",
    "print(merged_df[['cvd_mother_family_history']].value_counts(dropna=False))\n",
    "\n",
    "\n",
    "\n",
    "cvd_columns = [\n",
    "   'cvd_siblings_fam_q_1_a',\n",
    " 'cvd_siblings_fam_q_1_b',\n",
    " 'cvd_siblings_fam_q_1_c',\n",
    " 'cvd_siblings_fam_q_1_d',\n",
    " 'cvd_siblings_fam_q_1_e',\n",
    " 'cvd_siblings_fam_q_1_f',\n",
    "]\n",
    "\n",
    "def calculate_family_history(row):\n",
    "    \"\"\"\n",
    "    Calculate family history of CVD for the father.\n",
    "    - If any column has a value of 1 (Yes), return 1 (Yes).\n",
    "    - If all columns have a value of 0 (No), return 0 (No).\n",
    "    - If all columns are NaN, return NaN (Missing).\n",
    "    \"\"\"\n",
    "    if (row == '1').any():  # If any column has a value of 1 (Yes)\n",
    "        return 1\n",
    "    elif (row == '2').all():  # If all columns have a value of 0 (No)\n",
    "        return 0\n",
    "    else:  # If all columns are NaN or a mix of NaN and 0\n",
    "        return np.nan\n",
    "\n",
    "# Apply the function to create the new variable\n",
    "merged_df['cvd_siblings_family_history'] = merged_df[cvd_columns].apply(calculate_family_history, axis=1)\n",
    "\n",
    "# Check the results\n",
    "print(\"Value counts in 'cvd_siblings_family_history':\")\n",
    "print(merged_df[['cvd_siblings_family_history']].value_counts(dropna=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d82c6c5e-eef4-4c61-9510-1dfa7174731d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts in 'family_history':\n",
      "family_history\n",
      "NaN    54936\n",
      "1.0    43087\n",
      "0.0     2135\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define the function to calculate the final family history variable\n",
    "def calculate_final_family_history(row):\n",
    "    siblings = row[\"cvd_siblings_family_history\"]\n",
    "    mother = row[\"cvd_mother_family_history\"]\n",
    "    father = row[\"cvd_father_family_history\"]\n",
    "\n",
    "    # If any of the three variables is 1, return 1\n",
    "    if siblings == 1 or mother == 1 or father == 1:\n",
    "        return 1\n",
    "    # If all three variables are 0, return 0\n",
    "    elif siblings == 0 and mother == 0 and father == 0:\n",
    "        return 0\n",
    "    # If all three variables are NaN, return NaN\n",
    "    elif pd.isna(siblings) and pd.isna(mother) and pd.isna(father):\n",
    "        return np.nan\n",
    "    # If there is a mix of 0 and NaN, return 0\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Apply the function to create the final family history variable\n",
    "merged_df[\"family_history\"] = merged_df.apply(calculate_final_family_history, axis=1)\n",
    "\n",
    "# Check the results\n",
    "print(\"Value counts in 'family_history':\")\n",
    "print(merged_df[\"family_history\"].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "897711e0-d75b-47c1-be1e-40475b6cadbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "  'cvd_father_family_history', \n",
    "'cvd_mother_family_history', 'cvd_siblings_family_history',\n",
    "    'cvd_father_fam_q_1_a',\n",
    " 'cvd_father_fam_q_1_b',\n",
    " 'cvd_father_fam_q_1_c',\n",
    " 'cvd_father_fam_q_1_d',\n",
    " 'cvd_father_fam_q_1_e',\n",
    " 'cvd_father_fam_q_1_f',\n",
    " 'cvd_mother_fam_q_1_a',\n",
    " 'cvd_mother_fam_q_1_b',\n",
    " 'cvd_mother_fam_q_1_c',\n",
    " 'cvd_mother_fam_q_1_d',\n",
    " 'cvd_mother_fam_q_1_e',\n",
    " 'cvd_mother_fam_q_1_f',\n",
    " 'cvd_siblings_fam_q_1_a',\n",
    " 'cvd_siblings_fam_q_1_b',\n",
    " 'cvd_siblings_fam_q_1_c',\n",
    " 'cvd_siblings_fam_q_1_d',\n",
    " 'cvd_siblings_fam_q_1_e',\n",
    " 'cvd_siblings_fam_q_1_f', \n",
    "\n",
    "\n",
    "]\n",
    "merged_df = merged_df.drop(columns=columns_to_drop)  # 'errors=\"ignore\"' prevents errors if a column is missing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
