{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12272e64-730b-417d-886a-ab743d9a25ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('converted_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ece244f6-7380-4fdb-88c7-60a8a4de50e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_priority_vars = [\n",
    "    'Appetite changes',\n",
    "    'Physically abused by family as a child',\n",
    "    'Antidepressant use', \n",
    "    'CVD Family history'\n",
    "]\n",
    "\n",
    "# Keep rows missing â‰¤1 out of 4 variables (25% missingness allowed)\n",
    "threshold = 0.25  # Adjust based on your needs (0.10 = 10%)\n",
    "mask = df[high_priority_vars].isnull().mean(axis=1) <= threshold\n",
    "df_clean = df[mask]\n",
    "\n",
    "#% missingness\n",
    "missing_values_sum = df_clean.isna().sum()\n",
    "total_rows = df_clean.shape[0]\n",
    "missing_values_percentage = (missing_values_sum / total_rows) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74552737-52e6-47bd-87fc-ff50310590b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_missing_values_and_uniques(df):\n",
    "    # Calculate missing values percentage (only true NaN values)\n",
    "    missing_values_sum = df.isna().sum()\n",
    "    total_rows = df.shape[0]\n",
    "    missing_values_percentage = (missing_values_sum / total_rows) * 100\n",
    "    print(\"Original missing values (%):\")\n",
    "    print(missing_values_percentage)\n",
    "    \n",
    "    # Loop through each column\n",
    "    for column in df.columns:\n",
    "        print(f\"\\n--- Unique values for '{column}' ---\")\n",
    "        \n",
    "        # Special handling for ID columns\n",
    "        if column == 'project_pseudo_id':\n",
    "            num_unique = df[column].nunique()\n",
    "            print(f\"Total unique IDs: {num_unique} (expected 1 per participant)\")\n",
    "            print(f\"Duplicates found: {df[column].duplicated().sum()}\")\n",
    "            continue\n",
    "            \n",
    "        # Get value counts (including '$7' and other strings)\n",
    "        value_counts = df[column].value_counts(dropna=False).reset_index()\n",
    "        value_counts.columns = ['Unique Value', 'Count']\n",
    "        \n",
    "        # Calculate percentages safely\n",
    "        total_count = value_counts['Count'].sum()\n",
    "        \n",
    "        # Create percentage column with mixed types\n",
    "        percentages = []\n",
    "        for count in value_counts['Count']:\n",
    "            try:\n",
    "                pct = (float(count) / total_count) * 100\n",
    "                percentages.append(f\"{pct:.2f}%\")\n",
    "            except (TypeError, ValueError):\n",
    "                percentages.append(\"N/A\")\n",
    "        \n",
    "        value_counts['Percentage'] = percentages\n",
    "        display(value_counts)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe5c3a20-b719-41f6-9f4b-1ad4dccad740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Physical activity ---\n",
      "Mean: 4.35\n",
      "Standard Deviation: 2.20\n",
      "Range: 0.00 - 25.00\n",
      "\n",
      "--- Diastolic blood pressure ---\n",
      "Mean: 74.55\n",
      "Standard Deviation: 9.50\n",
      "Range: 35.00 - 143.00\n",
      "\n",
      "--- Systolic blood pressure ---\n",
      "Mean: 127.14\n",
      "Standard Deviation: 15.93\n",
      "Range: 72.00 - 225.00\n"
     ]
    }
   ],
   "source": [
    "# List of continuous variables to analyze\n",
    "continuous_vars = [\n",
    "     'Physical activity', \n",
    "    'Diastolic blood pressure', \n",
    "    'Systolic blood pressure', \n",
    "    # 'Age',\n",
    "    # 'Cholesterol', \n",
    "    # 'HDL cholesterol', \n",
    "    # 'LDL cholesterol', \n",
    "    # 'Triglycerides',\n",
    "    # 'Glucose', \n",
    "    # 'Glycated haemoglobin'\n",
    " \n",
    "]\n",
    "\n",
    "# Calculate and print stats for each variable\n",
    "for var in continuous_vars:\n",
    "    var_mean = df_clean[var].mean()\n",
    "    var_std = df_clean[var].std()\n",
    "    \n",
    "    print(f\"\\n--- {var} ---\")\n",
    "    print(f\"Mean: {var_mean:.2f}\")  # Rounded to 2 decimal places\n",
    "    print(f\"Standard Deviation: {var_std:.2f}\")\n",
    "    print(f\"Range: {df[var].min():.2f} - {df[var].max():.2f}\")  # Bonus: shows min/max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c7bf995-f68d-46ff-b78c-1c8e6c32e0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1276"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "num_cases = df_clean[df_clean['CVD'] == 1].shape[0]\n",
    "\n",
    "num_cases\n",
    "\n",
    "#stats = analyze_missing_values_and_uniques(df)\n",
    "#df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42e595cd-a461-4fe6-a84f-ff48f831454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "df = df_clean.copy()\n",
    "\n",
    "# Define columns properly\n",
    "ordinal_columns = [\n",
    "    'Childhood trauma score',\n",
    "    'Depressive symptoms score', 'Anxiety symptoms score',  \n",
    "    'Physically abused by family as a child',\n",
    "    'Felt hated by family member as a child',\n",
    "    'Sexually molested as a child',\n",
    "    'Someone to take to doctor when needed as a child',\n",
    "    'Felt loved', \n",
    "    'Hypertension', 'Smoking status', 'Physical activity', \n",
    "]\n",
    "\n",
    "true_categorical = [\n",
    "    'Depressed mood', 'Anhedonia', 'Appetite changes', 'Sleep problems',\n",
    "    'Psychomotor changes', 'Fatigue', 'Feelings of inadequacy',\n",
    "    'Cognitive problems', 'Suicidal ideation', 'Anxiety', 'Restlessness',\n",
    "    'Lack of relaxation',  'Concentration problems',\n",
    "    'Irritability', \n",
    "    'Antidepressant use', 'Diabetes', 'Gender',\n",
    "    'CVD Family history', 'CVD'\n",
    "]\n",
    "\n",
    "continuous_columns = [\n",
    "    'Diastolic blood pressure', 'Systolic blood pressure',\n",
    "    'Age', 'Cholesterol', 'HDL cholesterol', 'LDL cholesterol', 'Triglycerides',\n",
    "    'Glucose', 'Glycated haemoglobin'\n",
    "]\n",
    "\n",
    "# Create transformers WITHOUT scaling\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', IterativeImputer(max_iter=10, random_state=42))\n",
    "])\n",
    "\n",
    "ordinal_transformer = Pipeline([\n",
    "    ('imputer', IterativeImputer(max_iter=10, random_state=42))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "])\n",
    "\n",
    "# Combine transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, continuous_columns),\n",
    "        ('ord', ordinal_transformer, ordinal_columns),\n",
    "        ('cat', categorical_transformer, true_categorical)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Apply transformations\n",
    "df_imputed = pd.DataFrame(\n",
    "    preprocessor.fit_transform(df),\n",
    "    columns=continuous_columns + ordinal_columns + true_categorical\n",
    ")\n",
    "\n",
    "# Convert back to appropriate types\n",
    "for col in ordinal_columns + continuous_columns:\n",
    "    df_imputed[col] = df_imputed[col].round().astype(int) if col in ordinal_columns else df_imputed[col].astype(float)\n",
    "\n",
    "for col in true_categorical:\n",
    "    df_imputed[col] = df_imputed[col].astype('category')\n",
    "\n",
    "# Verify\n",
    "print(\"Missing values after imputation:\")\n",
    "print(df_imputed.isnull().sum().sum())  # Should be 0\n",
    "print(\"\\nFirst few rows of imputed data:\")\n",
    "print(df_imputed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f6fee2d-fb89-41c1-ae18-e02e7ea27590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Before imputation (pairwise complete)\n",
    "corr_before = df_clean[continuous_columns + ordinal_columns + true_categorical].corr(method='spearman')\n",
    "\n",
    "# After imputation\n",
    "corr_after = df_imputed[continuous_columns + ordinal_columns + true_categorical].corr(method='spearman')\n",
    "\n",
    "# Difference in correlations\n",
    "corr_diff = corr_after - corr_before\n",
    "print(\"\\nMaximum absolute correlation difference:\", corr_diff.abs().max().max())\n",
    "\n",
    "# Visualize correlation differences\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(corr_diff, cmap='coolwarm', vmin=-0.3, vmax=0.3)\n",
    "plt.colorbar()\n",
    "plt.title(\"Difference in Correlations (After - Before)\")\n",
    "plt.xticks(range(len(corr_diff.columns)), corr_diff.columns, rotation=90)\n",
    "plt.yticks(range(len(corr_diff.columns)), corr_diff.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d4ce923-0e70-43f3-af16-8e1fb744965b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 correlation changes:\n",
      "Anxiety insomnia           Depressive symptoms score   -0.174348\n",
      "Depressive symptoms score  Anxiety insomnia            -0.174348\n",
      "                           Anxiety fatigue             -0.157388\n",
      "Anxiety fatigue            Depressive symptoms score   -0.157388\n",
      "                           Anxiety symptoms score      -0.155103\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "corr_diff_unstacked = corr_diff.unstack().sort_values(key=abs, ascending=False)\n",
    "print(\"Top 5 correlation changes:\")\n",
    "print(corr_diff_unstacked.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0badd72-e8cf-494d-8643-6384e71b4342",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Outliers\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Define features for outlier detection\n",
    "features = [\n",
    "    'Diastolic blood pressure', 'Systolic blood pressure', \n",
    "    'Cholesterol', 'HDL cholesterol', 'LDL cholesterol', \n",
    "    'Triglycerides', 'Glucose', 'Glycated haemoglobin'\n",
    "]\n",
    "\n",
    "# Extract the subset for outlier detection\n",
    "features_data = df_imputed[features].copy()\n",
    "\n",
    "# Fit Isolation Forest\n",
    "iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
    "outlier_flags = iso_forest.fit_predict(features_data)\n",
    "\n",
    "# Create a mask for inliers (non-outliers)\n",
    "inlier_mask = outlier_flags != -1  # Inliers are marked as 1\n",
    "\n",
    "# Get cleaned feature data (outliers removed)\n",
    "cleaned_features = features_data[inlier_mask].copy()\n",
    "\n",
    "# Step 1: Get the indices of inliers (to align with original dataframe)\n",
    "inlier_indices = features_data[inlier_mask].index\n",
    "\n",
    "# Step 2: Select all columns from the original dataframe, but only keep rows that are inliers\n",
    "df_cleaned = df_imputed.loc[inlier_indices].copy()\n",
    "\n",
    "# Verify: The feature columns in df_cleaned should match cleaned_features\n",
    "assert df_cleaned[features].equals(cleaned_features), \"Mismatch in cleaned data!\"\n",
    "\n",
    "df_cleaned\n",
    "\n",
    "df_cleaned.to_csv(\"df_cleaned.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
